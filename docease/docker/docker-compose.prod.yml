version: '3.8'

# ============================================
# CONFIGURATION PRODUCTION
# ============================================
# Pour utiliser cette configuration :
# docker compose -f docker-compose.prod.yml up -d
# ============================================

services:
  postgres:
    image: postgres:16-alpine
    container_name: n8n-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-n8n}
      - POSTGRES_USER=${POSTGRES_USER:-n8n}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - n8n-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-n8n}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n-prod
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    environment:
      # Configuration n8n
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=${N8N_PORT:-5678}
      - N8N_PROTOCOL=${N8N_PROTOCOL:-https}
      - N8N_EDITOR_BASE_URL=${N8N_EDITOR_BASE_URL}
      - WEBHOOK_URL=${WEBHOOK_URL}
      
      # Base de données PostgreSQL
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB:-n8n}
      - DB_POSTGRESDB_USER=${POSTGRES_USER:-n8n}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      
      # Configuration générale (production)
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE:-Europe/Paris}
      - N8N_LOG_LEVEL=${N8N_LOG_LEVEL:-info}
      - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED:-false}
      
      # Email de validation (optionnel)
      - VALIDATION_EMAIL=${VALIDATION_EMAIL:-}
      
      # Authentification basique (recommandé en production)
      - N8N_BASIC_AUTH_ACTIVE=${N8N_BASIC_AUTH_ACTIVE:-true}
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD}
      
      # Configuration CORS
      - N8N_CORS_ENABLED=${N8N_CORS_ENABLED:-true}
      - N8N_CORS_ALLOW_ORIGIN=${N8N_CORS_ALLOW_ORIGIN:-*}
      
      # Workflows et templates
      - N8N_USER_FOLDER=/data/n8n
      - N8N_CUSTOM_EXTENSIONS=/data/n8n/custom
      
    volumes:
      # Données persistantes n8n
      - n8n_data:/home/node/.n8n
      
      # Templates Word (lecture seule)
      - ./../templates:/templates:ro
      
      # Workflows
      - ./../workflows:/workflows
      
    networks:
      - n8n-network
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: n8n-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - n8n-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-prod
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      # OPTIMISATIONS PERFORMANCES - Production
      - OLLAMA_KEEP_ALIVE=1h                # Garde le modèle plus longtemps
      - OLLAMA_NUM_PARALLEL=4                # Plus de requêtes simultanées
      - OLLAMA_MAX_LOADED_MODELS=1           # Charge 1 seul modèle à la fois
      - OLLAMA_FLASH_ATTENTION=1             # Active l'attention rapide
      - OLLAMA_NUM_GPU=1                     # Si GPU disponible
      - OLLAMA_NUM_THREAD=8                  # Plus de threads CPU
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - n8n-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
          # Décommentez si vous avez un GPU NVIDIA
          # devices:
          #   - driver: nvidia
          #     count: all
          #     capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Caddy - Reverse proxy HTTPS (alternative à Cloudflare Tunnel)
  # Décommentez si vous n'utilisez PAS Cloudflare Tunnel
  # caddy:
  #   # Image Caddy avec module rate limiting compilé
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.caddy
  #   container_name: n8n-caddy
  #   restart: unless-stopped
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #     - "443:443/udp"
  #   volumes:
  #     - ./Caddyfile:/etc/caddy/Caddyfile:ro
  #     - caddy_data:/data
  #     - caddy_config:/config
  #   networks:
  #     - n8n-network
  #   depends_on:
  #     - n8n
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  # Cloudflare Tunnel - Expose n8n publiquement sans ouvrir de ports
  # Décommentez si vous utilisez Cloudflare Tunnel au lieu de Caddy
  # cloudflared:
  #   image: cloudflare/cloudflared:latest
  #   container_name: n8n-cloudflared
  #   restart: unless-stopped
  #   command: tunnel --config /etc/cloudflared/config.yml run
  #   volumes:
  #     - ./cloudflared-config.yml:/etc/cloudflared/config.yml:ro
  #     - cloudflared_credentials:/etc/cloudflared:ro
  #   networks:
  #     - n8n-network
  #   depends_on:
  #     - n8n
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

networks:
  n8n-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  n8n_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  cloudflared_credentials:
    driver: local

